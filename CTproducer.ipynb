{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad2ea1b-1465-4b2b-b5e5-8443ad5824e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pandas\n",
    "#!pip3 install PyArrow\n",
    "from pyspark.sql.functions import col\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "96a1b218-ba77-4806-8908-2261eb8fe23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96231d36-2759-4b99-a768-0dbd9d664921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import datetime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087a9dcf-8224-4a14-b29d-3b597c662be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"/etc/hadoop/conf/hive-site.xml\"):\n",
    "    tree = ET.parse(\"/etc/hadoop/conf/hive-site.xml\")\n",
    "    root = tree.getroot()\n",
    "    for prop in root.findall(\"property\"):\n",
    "        if prop.find(\"name\").text == \"hive.metastore.warehouse.dir\":\n",
    "            storage = (\n",
    "                prop.find(\"value\").text.split(\"/\")[0]\n",
    "                + \"//\"\n",
    "                + prop.find(\"value\").text.split(\"/\")[2]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5560242e-5918-4867-aab9-0a858d20f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"STORAGE\"] = storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943ffdf3-2bc6-4105-834f-61b2568e2a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://go01-demo\n"
     ]
    }
   ],
   "source": [
    "print(storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1cb56f8-d789-4db5-911c-e3eb289e093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting spark.hadoop.yarn.resourcemanager.principal to pauldefusco\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"PythonSQL\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.s3guard.ddb.region\",\"us-east-2\")\\\n",
    "    .config(\"spark.yarn.access.hadoopFileSystems\",os.environ[\"STORAGE\"])\\\n",
    "    .config(\"spark.rpc.message.maxSize\", \"1024\")\\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\\\n",
    "    .getOrCreate()\n",
    " #   .config(\"spark.driver.cores\", 4)\\\n",
    " #   .config(\"spark.driver.memory\", \"8g\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ca15e-9d80-43f1-85ed-ada6bf998420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup clickthrough (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b1002e97-4695-46ba-b174-ab4661113198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\",\"true\").parquet(os.environ[\"STORAGE\"]+\"/cde-workshop/clickthrough/historical\",\n",
    "                                                    header=True,\n",
    "                                                    sep=',',\n",
    "                                                    nullValue='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13709afb-1a5d-4851-a582-8a6de9da1606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.format('parquet').mode(\"overwrite\").saveAsTable(\"default.CLICKTHROUGH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb54def-cc73-4e54-a3be-ea918ffff9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CT producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "314dd75b-9fdb-4760-b756-cfe6fb24cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "df = df.withColumn(\"converted_date\",df['hour'].cast(TimestampType()))\\\n",
    "            .withColumn('day', F.dayofmonth(\"converted_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e4c5b15f-abeb-4503-af75-5d2ed60db138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "yesterday = df.select(F.max(F.col('day'))).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f83db19-888b-4cd0-b6cc-59748aa64862",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = yesterday + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "adb85660-8d3d-4c4c-bd46-e2a06372d3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_batch_20141026\n"
     ]
    }
   ],
   "source": [
    "year = \"2014\"\n",
    "month = \"10\"\n",
    "today_string = \"csv_batch_\" + year + month + str(today)\n",
    "print(today_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6af2ae68-a796-4a6f-8d40-efa1bb03c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = spark.read.option(\"header\",\"true\").csv(os.environ[\"STORAGE\"]+\"/cde-workshop/clickthrough/{}\".format(today_string),\n",
    "                                                    header=True,\n",
    "                                                    sep=',',\n",
    "                                                    nullValue='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e166818-c706-4539-9a73-e22ff585a050",
   "metadata": {},
   "source": [
    "#### STRATEGY 1: Add Last Updated Column and Perform Incremental Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ff1c497-0630-4eb3-b37f-a7cfc6cdf8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd407601-3680-47b0-b6b3-39aa2179ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = batch_df.withColumn(\"LastUpdatedTimestamp\", F.to_timestamp(lit(year + month + str(today)), 'yyyyMMdd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f57ed13d-5c75-4478-89f5-ad5276ecdbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as View\n",
    "batch_df.createOrReplaceTempView(today_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "85aad74e-fb7a-427f-b900-871963faddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clickthrough_df = spark.sql(\"SELECT * FROM default.CLICKTHROUGH\").withColumn(\"LastUpdatedTimestamp\", F.to_timestamp(lit(year + month + str(yesterday)), 'yyyyMMdd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8570c8bd-624e-4d89-8734-564bc5ba262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clickthrough_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "657237e3-8d70-446c-b839-20e59be78bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert QUINN ASSERTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "77052ea1-51d5-4305-99ad-f07eb67a9979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('click', 'string'),\n",
       " ('hour', 'string'),\n",
       " ('C1', 'string'),\n",
       " ('banner_pos', 'string'),\n",
       " ('site_id', 'string'),\n",
       " ('site_domain', 'string'),\n",
       " ('site_category', 'string'),\n",
       " ('app_id', 'string'),\n",
       " ('app_domain', 'string'),\n",
       " ('app_category', 'string'),\n",
       " ('device_id', 'string'),\n",
       " ('device_ip', 'string'),\n",
       " ('device_model', 'string'),\n",
       " ('device_type', 'string'),\n",
       " ('device_conn_type', 'string'),\n",
       " ('C14', 'string'),\n",
       " ('C15', 'string'),\n",
       " ('C16', 'string'),\n",
       " ('C17', 'string'),\n",
       " ('C18', 'string'),\n",
       " ('C19', 'string'),\n",
       " ('C20', 'string'),\n",
       " ('C21', 'string'),\n",
       " ('LastUpdatedTimestamp', 'timestamp')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickthrough_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb37aff8-53bb-4903-9c96-9177cbb6a3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('click', 'string'),\n",
       " ('hour', 'string'),\n",
       " ('C1', 'string'),\n",
       " ('banner_pos', 'string'),\n",
       " ('site_id', 'string'),\n",
       " ('site_domain', 'string'),\n",
       " ('site_category', 'string'),\n",
       " ('app_id', 'string'),\n",
       " ('app_domain', 'string'),\n",
       " ('app_category', 'string'),\n",
       " ('device_id', 'string'),\n",
       " ('device_ip', 'string'),\n",
       " ('device_model', 'string'),\n",
       " ('device_type', 'string'),\n",
       " ('device_conn_type', 'string'),\n",
       " ('C14', 'string'),\n",
       " ('C15', 'string'),\n",
       " ('C16', 'string'),\n",
       " ('C17', 'string'),\n",
       " ('C18', 'string'),\n",
       " ('C19', 'string'),\n",
       " ('C20', 'string'),\n",
       " ('C21', 'string'),\n",
       " ('LastUpdatedTimestamp', 'timestamp')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ab013c2-685e-4355-b804-125951c48a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING =   \"\"\"\n",
    "  SELECT unioned.*\n",
    "  FROM (\n",
    "    SELECT * FROM default.CLICKTHROUGH_with_ts x\n",
    "    UNION ALL\n",
    "    SELECT * FROM {0} y\n",
    "  ) unioned\n",
    "  JOIN\n",
    "  (\n",
    "    SELECT\n",
    "      id,\n",
    "      max(LastUpdatedTimestamp) as max_date\n",
    "    FROM (\n",
    "      SELECT * FROM default.CLICKTHROUGH_with_ts\n",
    "      UNION ALL\n",
    "      SELECT * FROM {0}\n",
    "    ) t\n",
    "    GROUP BY\n",
    "      id\n",
    "  ) grouped\n",
    "  ON\n",
    "    unioned.id = grouped.id AND\n",
    "    unioned.LastUpdatedTimestamp = grouped.max_date\n",
    "  \"\"\".format(today_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed3ff2ad-6496-4e33-864b-71dbc7c2091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_df = spark.sql(SQL_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2b01de80-46e4-4e85-93af-cc290423cee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "union_df.write.format('parquet').mode(\"overwrite\").saveAsTable(\"default.CLICKTHROUGH_{}\".format(today_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "469d3727-eb65-48c7-a17f-58dce400ea64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23609479"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/26 04:45:24 490 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /100.100.16.77:52102 is closed\n"
     ]
    }
   ],
   "source": [
    "union_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7cbe4-bb77-43fb-a364-966a52ac82f5",
   "metadata": {},
   "source": [
    "#### STRATEGY 2: Incremental Merge via Union and Repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c99090cf-31ca-4fcb-86a0-8571857e2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = spark.read.option(\"header\",\"true\").csv(os.environ[\"STORAGE\"]+\"/cde-workshop/clickthrough/{}\".format(today_string),\n",
    "                                                    header=True,\n",
    "                                                    sep=',',\n",
    "                                                    nullValue='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7e7f1aab-9e54-4d0e-ad26-9cbcc497642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clickthrough_df = spark.sql(\"SELECT * FROM default.CLICKTHROUGH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8ceff661-b16b-47ed-8558-c7466c636934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "49cfb88b-142a-4cfb-8510-21486f71720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clickthrough_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7ccc048-3e11-449c-b567-f8f2e2b625d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = batch_df.unionAll(clickthrough_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2627184d-3bbf-4ab9-b53d-39bf93d90ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_merge.withColumn(\"converted_date\",df_merge['hour'].cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "58914960-c46e-4487-b5a1-f884bca59727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_merge.withColumn(\"_row_number\", F.row_number().over(Window.partitionBy(df_merge['id']).orderBy('converted_date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "99b29c4d-155d-4656-8f6b-41858d546150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_merge.where(df_merge._row_number == 1).drop(\"_row_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "426252ef-4480-475e-a795-83f4a4ba55b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23609479"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3169a1-b471-402b-ac97-d183743c2c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
